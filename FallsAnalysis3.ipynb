{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4193266,"sourceType":"datasetVersion","datasetId":2472961}],"dockerImageVersionId":30260,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Credit Fraud Detection\n\nAnonymized credit card transactions labeled as fraudulent or genuine\n\n* Source: https://www.kaggle.com/datasets/whenamancodes/fraud-detection\n\n## About Data\nThe dataset contains transactions made by credit cards in September 2013 by European cardholders.\nThis dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n\n\nIt contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, … V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-sensitive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n\n\nGiven the class imbalance ratio, we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC). Confusion matrix accuracy is not meaningful for unbalanced classification.","metadata":{}},{"cell_type":"markdown","source":"# 1. Importing relevant libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\nfrom collections import Counter\n\nsns.set()\n%matplotlib inline","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Loading raw data","metadata":{}},{"cell_type":"code","source":"df_raw = pd.read_csv('../input/fraud-detection/creditcard.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. EDA","metadata":{}},{"cell_type":"code","source":"df_raw.describe(include='all')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. \n# It looks like unimportant. We'll drop that.\n\ndf=df_raw.drop(['Time'], axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We have no null values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# All categories are numerical (except target 'Class' which is boolean)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df[df['Class'] == 1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df[df['Class'] == 0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# There is a huge disproportion in data. Only 0,17% is a fraud data.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.countplot(x='Class',data=df)\ntotal = float(len(df))\nfor p in ax.patches:\n    percentage=\"{:.2f}%\".format(100 * p.get_height()/total)\n    x = p.get_x() + p.get_width()\n    y = p.get_height()\n    ax.annotate(percentage, (x, y),ha=\"center\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correlations and most important features","metadata":{}},{"cell_type":"code","source":"df.corr()['Class'].sort_values()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,8))\nd = df.corr()['Class'][:-1].abs().sort_values().plot(kind='bar', title='Most important features')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's peak all features with correlation 0.15 and morec = \n\nc = df.corr()['Class'][:-1].abs() > 0.15\n\nprint (c)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.jointplot(x='V17', y='V14',hue='Class', data=df, palette = 'dark')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.jointplot(x='V17', y='V12',hue='Class', data=df, palette = 'dark')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.jointplot(x='V17', y='V10',hue='Class', data=df, palette = 'dark')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.jointplot(x='V14', y='V12',hue='Class', data=df, palette = 'dark')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Feature engineering","metadata":{}},{"cell_type":"markdown","source":"## Outlier detection","metadata":{}},{"cell_type":"markdown","source":"Let's check the distribution of the features with 0,13 and higher and correlation","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=3, ncols=3,figsize=(13,8))\n\naxes[0,0].hist(df['V17'], bins=60, linewidth=0.5, edgecolor=\"white\")\naxes[0,0].set_title(\"V17 distribution\");\n\naxes[0,1].hist(df['V10'], bins=60, linewidth=0.5, edgecolor=\"white\")\naxes[0,1].set_title(\"V10 distribution\");\n\naxes[0,2].hist(df['V12'], bins=60, linewidth=0.5, edgecolor=\"white\")\naxes[0,2].set_title(\"V12 distribution\");\n\naxes[1,0].hist(df['V16'], bins=60, linewidth=0.5, edgecolor=\"white\")\naxes[1,0].set_title(\"V16 distribution\");\n\naxes[1,1].hist(df['V14'], bins=60, linewidth=0.5, edgecolor=\"white\")\naxes[1,1].set_title(\"V14 distribution\");\n\naxes[1,2].hist(df['V3'], bins=60, linewidth=0.5, edgecolor=\"white\")\naxes[1,2].set_title(\"V3 distribution\");\n\naxes[2,0].hist(df['V7'], bins=60, linewidth=0.5, edgecolor=\"white\")\naxes[2,0].set_title(\"V7 distribution\");\n\naxes[2,1].hist(df['V11'], bins=60, linewidth=0.5, edgecolor=\"white\")\naxes[2,1].set_title(\"V11 distribution\");\n\naxes[2,2].hist(df['V4'], bins=60, linewidth=0.5, edgecolor=\"white\")\naxes[2,2].set_title(\"V4 distribution\");\n\nplt.tight_layout()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It looks like we have a lot of outliers here. We can try to get rid of them.","metadata":{}},{"cell_type":"markdown","source":"## Tukey's IQR method\n\nTukey’s  (1977)  technique  is  used  to  detect  outliers  in  univariate  distributions  for symmetric as well as in slightly skewed data sets. The general rule is that anything not in the range of (Q1 - 1.5 IQR) and (Q3 + 1.5 IQR) is an outlier, and can be removed. ","metadata":{}},{"cell_type":"code","source":"def detect_outliers(df,n,features):\n    \"\"\"\n    Takes a dataframe df of features and returns an index list corresponding to the observations \n    containing more than n outliers according to the Tukey IQR method.\n    \"\"\"\n    outlier_indices = []\n    \n    # iterating over features(columns)\n    for col in features:\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[col], 25)\n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[col],75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5 * IQR\n        \n        # Determining a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        \n        # appending the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        \n    # selecting observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    \n    return multiple_outliers   \n\n# detecting outliers\nOutliers_IQR = detect_outliers(df,2,['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'])\n\n# dropping outliers\ndf_out = df.drop(Outliers_IQR, axis = 0).reset_index(drop=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(Outliers_IQR)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_out","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking distributions of most important features after dropping outliers\n\nfig, axes = plt.subplots(nrows=3, ncols=3,figsize=(13,8))\n\naxes[0,0].hist(df_out['V17'], bins=60, linewidth=0.5, edgecolor=\"white\")\naxes[0,0].set_title(\"V17 distribution\");\n\naxes[0,1].hist(df_out['V10'], bins=60, linewidth=0.5, edgecolor=\"white\")\naxes[0,1].set_title(\"V10 distribution\");\n\naxes[0,2].hist(df_out['V12'], bins=60, linewidth=0.5, edgecolor=\"white\")\naxes[0,2].set_title(\"V12 distribution\");\n\naxes[1,0].hist(df_out['V16'], bins=60, linewidth=0.5, edgecolor=\"white\")\naxes[1,0].set_title(\"V16 distribution\");\n\naxes[1,1].hist(df_out['V14'], bins=60, linewidth=0.5, edgecolor=\"white\")\naxes[1,1].set_title(\"V14 distribution\");\n\naxes[1,2].hist(df_out['V3'], bins=60, linewidth=0.5, edgecolor=\"white\")\naxes[1,2].set_title(\"V3 distribution\");\n\naxes[2,0].hist(df_out['V7'], bins=60, linewidth=0.5, edgecolor=\"white\")\naxes[2,0].set_title(\"V7 distribution\");\n\naxes[2,1].hist(df_out['V11'], bins=60, linewidth=0.5, edgecolor=\"white\")\naxes[2,1].set_title(\"V11 distribution\");\n\naxes[2,2].hist(df_out['V4'], bins=60, linewidth=0.5, edgecolor=\"white\")\naxes[2,2].set_title(\"V4 distribution\");\n\nplt.tight_layout()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now features look much more \"normal\"!","metadata":{}},{"cell_type":"code","source":"# Let's check if we didn't drop too many important information accidentally","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print ('The amount of frauds in df before dropping outliers: ', len(df[df['Class'] == 1]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print ('The amount of frauds in df afret dropping outliers: ', len(df_out[df_out['Class'] == 1]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It looks like outliers are very similar to fraud values and we dropped most of them!\n\nLet's create a new df with dropped outliers only.","metadata":{}},{"cell_type":"code","source":"Outliers_df2 = df.loc[df.index[Outliers_IQR]]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(Outliers_df2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Outliers_df2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Modelling","metadata":{}},{"cell_type":"markdown","source":"## 1st data frame","metadata":{}},{"cell_type":"code","source":"# Train/Test split\n\nX = Outliers_df2.drop('Class',axis=1).values\ny = Outliers_df2['Class'].values\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scaling data\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(X_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Dropout","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\n# https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n\nmodel.add(Dense(units=29,activation='relu'))\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(units=14,activation='relu'))\nmodel.add(Dropout(0.1))\n\nmodel.add(Dense(units=7,activation='relu'))\n#model.add(Dropout(0.1))\n\nmodel.add(Dense(units=2,activation='relu'))\n\nmodel.add(Dense(units=1,activation='sigmoid'))\n\n# For a binary classification problem\nmodel.compile(loss='binary_crossentropy', optimizer='adam')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=35)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(x=X_train, \n          y=y_train, \n          epochs=3000,\n          validation_data=(X_test, y_test), verbose=2,\n          callbacks=[early_stop]\n          )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_loss = pd.DataFrame(model.history.history)\nmodel_loss.plot()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = (model.predict(X_test) > 0.5)*1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://en.wikipedia.org/wiki/Precision_and_recall\nprint(classification_report(y_test,predictions))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(y_test,predictions))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm_df = pd.DataFrame(confusion_matrix(y_test,predictions))\ncm_df.columns = ['Predicted 0','Predicted 1']\ncm_df = cm_df.rename(index={0: 'Actual 0',1:'Actual 1'})\ncm_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1 = f1_score(y_test, predictions)\nprint (f1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CM = confusion_matrix(y_test,predictions)\n\nTN = CM[0][0]\nFN = CM[1][0]\nTP = CM[1][1]\nFP = CM[0][1]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sensitivity, hit rate, recall, or true positive rate\nTPR = TP/(TP+FN)\n# Specificity or true negative rate\nTNR = TN/(TN+FP) \n# Precision or positive predictive value\nPPV = TP/(TP+FP)\n# Negative predictive value\nNPV = TN/(TN+FN)\n# Fall out or false positive rate\nFPR = FP/(FP+TN)\n# False negative rate\nFNR = FN/(TP+FN)\n# False discovery rate\nFDR = FP/(TP+FP)\n\n# Overall accuracy\nACC = (TP+TN)/(TP+FP+FN+TN)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ACC","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2nd data frame","metadata":{}},{"cell_type":"code","source":"# Train/Test split\n\nX = df_out.drop('Class',axis=1).values\ny = df_out['Class'].values\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\n# https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n\nmodel.add(Dense(units=29,activation='relu'))\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(units=14,activation='relu'))\nmodel.add(Dropout(0.1))\n\nmodel.add(Dense(units=7,activation='relu'))\n#model.add(Dropout(0.1))\n\nmodel.add(Dense(units=2,activation='relu'))\n\nmodel.add(Dense(units=1,activation='sigmoid'))\n\n# For a binary classification problem\nmodel.compile(loss='binary_crossentropy', optimizer='adam')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=35)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(x=X_train, \n          y=y_train, \n          epochs=3000,\n          validation_data=(X_test, y_test), verbose=2,\n          callbacks=[early_stop]\n          )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_loss = pd.DataFrame(model.history.history)\nmodel_loss.plot()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_2nd = (model.predict(X_test) > 0.5)*1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://en.wikipedia.org/wiki/Precision_and_recall\nprint(classification_report(y_test,predictions_2nd))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(y_test,predictions_2nd))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm_df = pd.DataFrame(confusion_matrix(y_test,predictions_2nd))\ncm_df.columns = ['Predicted 0','Predicted 1']\ncm_df = cm_df.rename(index={0: 'Actual 0',1:'Actual 1'})\ncm_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CM = confusion_matrix(y_test,predictions_2nd)\n\nTN_2nd = CM[0][0]\nFN_2nd = CM[1][0]\nTP_2nd = CM[1][1]\nFP_2nd = CM[0][1]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sensitivity, hit rate, recall, or true positive rate\nTPR_2nd = TP_2nd/(TP_2nd+FN_2nd)\n# Specificity or true negative rate\nTNR_2nd = TN_2nd/(TN_2nd+FP_2nd) \n# Precision or positive predictive value\nPPV_2nd = TP_2nd/(TP_2nd+FP_2nd)\n# Negative predictive value\nNPV_2nd = TN_2nd/(TN_2nd+FN_2nd)\n# Fall out or false positive rate\nFPR_2nd = FP_2nd/(FP_2nd+TN_2nd)\n# False negative rate\nFNR_2nd = FN_2nd/(TP_2nd+FN_2nd)\n# False discovery rate\nFDR_2nd = FP_2nd/(TP_2nd+FP_2nd)\n\n# Overall accuracy\nACC_2nd = (TP_2nd+TN_2nd)/(TP_2nd+FP_2nd+FN_2nd+TN_2nd)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ACC_2nd","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_2nd = f1_score(y_test, predictions_2nd)\nprint (f1_2nd)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Combining results","metadata":{}},{"cell_type":"code","source":"# COmbining both confusion matrices\n\nTN_final = TN + TN_2nd\nFN_final = FN + FN_2nd\nTP_final = TP + TP_2nd\nFP_final = FP + FP_2nd\n\n# Sensitivity, hit rate, recall, or true positive rate\nTPR_final = TP_final/(TP_final+FN_final)\n\n# Precision or positive predictive value\nPPV_final = TP_final/(TP_final+FP_final)\n\n# Overall accuracy\nACC_final = (TP_final+TN_final)/(TP_final+FP_final+FN_final+TN_final)\n\nF1_score = 2*((PPV_final*TPR_final)/(PPV_final+TPR_final))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm_df = pd.DataFrame(np.array([[TN_final, FP_final], [FN_final, TP_final]]), columns=['Predicted 0', 'Predicted 1'])\ncm_df = cm_df.rename(index={0: 'Actual 0',1:'Actual 1'})\n\ncm_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Combined confusion matrix","metadata":{}},{"cell_type":"code","source":"print('Overall accuracy final score: ', ACC_final)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Overall F1 final score: ', F1_score)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}